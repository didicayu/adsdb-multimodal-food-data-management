# ============================================================================
# EXPERIMENT CONFIGURATION
# Configuration file for CLIP fine-tuning experiments
# ============================================================================

# ----------------------------------------------------------------------------
# MINIO CONFIGURATION
# ----------------------------------------------------------------------------
minio:
  bucket: "fine-tuning-zone"
  prefixes:
    datasets: "datasets"
    images: "images"
    experiments: "experiments"

# ----------------------------------------------------------------------------
# DATASET CONFIGURATION
# ----------------------------------------------------------------------------
dataset:
  # Test manifest (already split from baseline)
  test_manifest_key: "datasets/test_pairs_positive.csv"
  
  # Training dataset (for LoRA fine-tuning)
  train_manifest_key: "datasets/train_pairs_augmented_with_negatives.csv"
  
  # Filter: only use positive pairs (label=1) for training
  filter_positive_only: true

# ----------------------------------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------------------------------
model:
  # CLIP model variant (Hugging Face model IDs)
  name: "openai/clip-vit-base-patch32"
  
  # Device selection: "cuda" or "cpu" (auto-detected if not specified)
  # Leave empty/null to auto-detect
  device: null
  
  # Batch size for embedding generation (evaluation)
  batch_size: 32

# ----------------------------------------------------------------------------
# EVALUATION CONFIGURATION
# ----------------------------------------------------------------------------
evaluation:
  # K values for Recall@K
  k_values: [1, 5, 10]
  
  # Compute MRR (Mean Reciprocal Rank)
  compute_mrr: true
  
  # Compute median rank (first hit) - optional, defaults to true
  compute_median_rank: true
  
  # Number of qualitative examples to generate
  n_examples: 5

# ----------------------------------------------------------------------------
# EXPERIMENT METADATA
# ----------------------------------------------------------------------------
experiment:
  # Experiment method/variant
  # Options: "baseline", "lora", "qlora", "full_finetune"
  # Change this to "lora" when running the LoRA fine-tuning notebook
  method: "baseline"
  
  # Output directory in MinIO (relative to bucket)
  results_dir: "experiments"

# ----------------------------------------------------------------------------
# LORA FINE-TUNING CONFIGURATION
# ----------------------------------------------------------------------------
lora:
  # LoRA rank
  r: 8
  
  # LoRA alpha
  lora_alpha: 16
  
  # LoRA dropout
  lora_dropout: 0.05
  
  # Bias: "none", "all", or "lora_only"
  bias: "none"
  
  # Target modules for LoRA adapters
  target_modules: ["q_proj", "k_proj", "v_proj", "out_proj"]
  
  # LoRA scope: "vision", "text", or "both"
  scope: "both"
  
  # Train only LoRA parameters (freeze base model)
  train_only_lora: true
  
  # Train logit_scale (temperature parameter)
  train_logit_scale: true

# ----------------------------------------------------------------------------
# TRAINING CONFIGURATION
# ----------------------------------------------------------------------------
training:
  # Learning rate
  learning_rate: 0.0001
  
  # Number of epochs
  num_epochs: 3
  
  # Batch size for training
  batch_size: 2
  
  # Gradient accumulation steps (effective batch = batch_size * gradient_accumulation_steps)
  gradient_accumulation_steps: 16
  
  # Warmup steps
  warmup_steps: 100
  
  # Logging steps (log every N optimizer steps)
  logging_steps: 50
  
  # Save steps (save checkpoint every N optimizer steps)
  save_steps: 500
  
  # Random seed for reproducibility
  random_seed: 42

# ----------------------------------------------------------------------------
# REPRODUCIBILITY
# ----------------------------------------------------------------------------
reproducibility:
  # Fixed random seeds
  random_seed: 42
  numpy_seed: 42
  torch_seed: 42
