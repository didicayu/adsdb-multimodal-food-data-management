# ============================================================================
# EXPERIMENT CONFIGURATION
# Configuration file for CLIP fine-tuning experiments
# ============================================================================

# ----------------------------------------------------------------------------
# DATASET CONFIGURATION
# ----------------------------------------------------------------------------
dataset:
  # Input dataset (augmented with positives and negatives)
  input_key: "datasets/train_pairs_augmented_with_negatives.csv"
  
  # Filter: only use positive pairs (label=1) for training/evaluation
  filter_positive_only: true
  
  # Train/test split
  test_size: 0.2  # 80% train, 20% test
  random_seed: 42
  split_by_recipe: true  # Critical: split by recipe_id to avoid leakage
  
  # Output manifests
  train_manifest_key: "datasets/train_manifest.csv"
  test_manifest_key: "datasets/test_manifest.csv"
  dataset_report_key: "datasets/dataset_report.json"

# ----------------------------------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------------------------------
model:
  # CLIP model variant (Hugging Face model IDs)
  # Options: 
  #   "openai/clip-vit-base-patch32" (ViT-B/32)
  #   "openai/clip-vit-base-patch16" (ViT-B/16)
  #   "openai/clip-vit-large-patch14" (ViT-L/14)
  #   "openai/clip-rn50", "openai/clip-rn101", etc.
  name: "openai/clip-vit-base-patch32"
  
  # Device
  device: "cuda"  # "cuda" or "cpu"
  
  # Batch size for embedding generation
  batch_size: 32

# ----------------------------------------------------------------------------
# EVALUATION CONFIGURATION
# ----------------------------------------------------------------------------
evaluation:
  # K values for Recall@K
  k_values: [1, 5, 10]
  
  # Compute MRR (Mean Reciprocal Rank)
  compute_mrr: true
  
  # Number of qualitative examples to generate
  n_examples: 5

# ----------------------------------------------------------------------------
# EXPERIMENT METADATA
# ----------------------------------------------------------------------------
experiment:
  # Experiment method/variant
  # Options: "baseline", "lora", "qlora", "full_finetune"
  method: "baseline"
  
  # Run ID will be auto-generated as: {method}_{timestamp}
  # Format: YYYYMMDD_HHMMSS
  
  # Output directory in MinIO
  results_dir: "experiments"
  
  # Results files
  results_key: "experiments/{method}/results_{method}.json"
  examples_key: "experiments/{method}/examples_top5.json"

# ----------------------------------------------------------------------------
# BASELINE SPECIFIC (M0)
# ----------------------------------------------------------------------------
baseline:
  # No fine-tuning parameters needed
  # Model is used as-is from pre-trained weights
  frozen: true

# ----------------------------------------------------------------------------
# FINE-TUNING PARAMETERS (for future experiments)
# ----------------------------------------------------------------------------
# fine_tuning:
#   # Learning rate
#   learning_rate: 1e-5
#   
#   # Number of epochs
#   num_epochs: 5
#   
#   # Batch size for training
#   batch_size: 32
#   
#   # LoRA parameters (if using LoRA/QLoRA)
#   lora:
#     r: 16
#     alpha: 32
#     dropout: 0.1
#     target_modules: ["visual", "transformer"]
#   
#   # QLoRA parameters
#   qlora:
#     bits: 4
#     use_double_quant: true
#     quant_type: "nf4"

# ----------------------------------------------------------------------------
# REPRODUCIBILITY
# ----------------------------------------------------------------------------
reproducibility:
  # Fixed random seeds
  random_seed: 42
  numpy_seed: 42
  torch_seed: 42
  
  # Save full configuration with each run
  save_config: true
  
  # Track library versions
  track_versions: true

